{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the training data\n",
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Constant to indicate +1 and 0 for classification\n",
    "BINARY_CLASSIFICATOIN_0 = -1\n",
    "BINARY_CLASSIFICATOIN_1 = 1\n",
    "\n",
    "def least_squares(y, tx):\n",
    "    return np.linalg.solve(tx.T @ tx, tx.T @ y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(weights, y, xT):\n",
    "    \"\"\"Returns the percentage of successful classifications for the weights,\n",
    "    given the expected results (y) and data (xT)\"\"\"\n",
    "    from proj1_helpers import predict_labels\n",
    "    compare_pred = predict_labels(weights, xT).reshape((len(y), 1))\n",
    "#     print(compare_pred.shape)\n",
    "#     print(y.reshape((len(y), 1)))\n",
    "    compare_pred -= y.reshape((len(y), 1))\n",
    "#     print(compare_pred.shape)\n",
    "\n",
    "    non_zero = 0\n",
    "    for i in range(len(compare_pred)):\n",
    "        if compare_pred[i] != 0:\n",
    "            non_zero += 1\n",
    "            \n",
    "    return 1 - non_zero / compare_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def standardize_0123_helper(x):\n",
    "    \"\"\"\n",
    "    Helper function that standardize the input data to mean 0 stddev 1. \n",
    "    The function replace all the -999 entries with the mean of all non -999\n",
    "    entries. \n",
    "    \"\"\"\n",
    "    for i in range(x.shape[1]):\n",
    "        mean = np.mean(x[np.where(x[:, i] != -999), i])\n",
    "        x[np.where(x[:, i] == -999), i] = mean \n",
    "        x[np.where(x[:, i] != -999), i] = x[np.where(x[:, i] != -999), i] - mean\n",
    "    \n",
    "    std_x = np.std(x, axis=0)\n",
    "    x[:, std_x > 0] = x[:, std_x > 0] / std_x[std_x > 0]\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def standardize_0(x):\n",
    "    \"\"\"\n",
    "    Standardize function for PRI_jet_num is 0\n",
    "    Return a standardize version of the original feature, with\n",
    "    uselessful thrown away\n",
    "    \"\"\"\n",
    "    # the features left that are meaningful and useful for training\n",
    "    feature_left = np.array([0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21])\n",
    "    left_x = np.zeros((x.shape[0], len(feature_left)))\n",
    "    left_x[:, :] = x[:, feature_left]\n",
    "    return standardize_0123_helper(left_x)\n",
    "    \n",
    "\n",
    "def standardize_1(x):\n",
    "    \"\"\"\n",
    "    Standardize function for PRI_jet_num is 1\n",
    "    Return a standardize version of the original feature, with\n",
    "    uselessful thrown away\n",
    "    \"\"\"\n",
    "    # the features left that are meaningful and useful for training\n",
    "    feature_left = np.array([0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 29])\n",
    "    left_x = np.zeros((x.shape[0], len(feature_left)))\n",
    "    left_x[:, :] = x[:, feature_left]\n",
    "    return standardize_0123_helper(left_x)\n",
    "    \n",
    "    \n",
    "def standardize_23(x):\n",
    "    \"\"\"\n",
    "    Standardize function for PRI_jet_num is 2 or 3\n",
    "    Return a standardize version of the original feature, with\n",
    "    uselessful thrown away\n",
    "    \"\"\"\n",
    "    # the features left that are meaningful and useful for training\n",
    "    feature_left = np.delete(np.arange(30), 22)\n",
    "    left_x = np.zeros((x.shape[0], len(feature_left)))\n",
    "    left_x[:, :] = x[:, feature_left]\n",
    "    return standardize_0123_helper(left_x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The column index for PRI_jet_num\n",
    "jet_num_col = 22\n",
    "\n",
    "def split_dataset_wrt22(x):\n",
    "    \"\"\"\n",
    "    Return three tuples of indices that splits x with respect to\n",
    "    feature 22 - PRI_jet_num.\n",
    "    First  Tuple of indicies: index in x where PRI_jet_num is 0\n",
    "    Second Tuple of indicies: index in x where PRI_jet_num is 1\n",
    "    Third  Tuple of indicies: index in x where PRI_jet_num is 2 or 3\n",
    "    \"\"\"\n",
    "    x_22_0 = np.where(x[:, jet_num_col] == 0)\n",
    "    x_22_1 = np.where(x[:, jet_num_col] == 1)\n",
    "    x_22_23 = np.where(x[:, jet_num_col] >= 2)\n",
    "    return x_22_0, x_22_1, x_22_23\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_poly(x, degree):\n",
    "    \"\"\"\n",
    "    Build the polynomial rising to the pass in parameter degree. \n",
    "    Return a matrix that has the same entry as pass in x, while \n",
    "    more features added accroding to degree. \n",
    "    Each individual feature is a some power of the original feature.\n",
    "    \"\"\"\n",
    "    matrix = np.zeros((x.shape[0], x.shape[1] * (degree + 1)))\n",
    "    for i in range(degree + 1):\n",
    "        matrix[:, (i * x.shape[1]) : ((i + 1) * x.shape[1])] = (x ** i)[:]\n",
    "        \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_feature_helper(x, op, ori_shape):\n",
    "    \"\"\"\n",
    "    Helper function that takes in x, an operator op, and the\n",
    "    original shape of x. \n",
    "    Return a matrix that is expanded with the feature added.\n",
    "    The matrix will have the same entries as x, but additional\n",
    "    ori_shape columns of feature added. \n",
    "    \"\"\"\n",
    "    matrix = np.zeros((x.shape[0], x.shape[1] + ori_shape))\n",
    "    matrix[:, : x.shape[1]] = x[:, :]\n",
    "    matrix[:, x.shape[1] : ] = op(x[:, : ori_shape])\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def add_feature(x):\n",
    "    \"\"\"\n",
    "    Add some features that we consider as useful and meaningful\n",
    "    to the data and good for training. \n",
    "    Return a modified x with features added. \n",
    "    \"\"\"\n",
    "    original_d = x.shape[1]\n",
    "    x = add_feature_helper(x, np.sin, original_d)\n",
    "    x = add_feature_helper(x, np.tanh, original_d)\n",
    "#     x = add_feature_helper(x, np.sin, original_d)\n",
    "    return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without additional feature\n",
      "0  Size:  99913 \tPerformance:  0.7190956131834696\n",
      "1  Size:  77544 \tPerformance:  0.6770607655008769\n",
      "23 Size:  72543 \tPerformance:  0.7231710847359497\n",
      "Overall:  0.70724\n",
      "******* \n",
      "WITH additional feature\n",
      "0  Size:  99913 \tPerformance:  0.8247074955211033\n",
      "1  Size:  77544 \tPerformance:  0.7411920973898689\n",
      "23 Size:  72543 \tPerformance:  0.7672001433632466\n",
      "Overall:  0.782116\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split the data\n",
    "i_0, i_1, i_23 = split_dataset_wrt22(tX)\n",
    "tx_0 =  tX[i_0]\n",
    "y_0 =   y[i_0]\n",
    "tx_1 =  tX[i_1]\n",
    "y_1 =   y[i_1]\n",
    "tx_23 = tX[i_23]\n",
    "y_23 =  y[i_23]\n",
    "\n",
    "# Standardize the data\n",
    "std_tx_0 = standardize_0(tx_0)\n",
    "std_tx_1 = standardize_1(tx_1)\n",
    "std_tx_23 = standardize_23(tx_23)\n",
    "\n",
    "\n",
    "print(\"Without additional feature\")\n",
    "# Add the feature\n",
    "# std_tx_0 = add_feature(std_tx_0)\n",
    "# std_tx_1 = add_feature(std_tx_1)\n",
    "# std_tx_23 = add_feature(std_tx_23)\n",
    "\n",
    "weights_0 = least_squares(y_0, std_tx_0)\n",
    "weights_1 = least_squares(y_1, std_tx_1)\n",
    "weights_23 = least_squares(y_23, std_tx_23)\n",
    "\n",
    "p0 = performance(weights_0, y_0, std_tx_0)\n",
    "p1 = performance(weights_1, y_1, std_tx_1)\n",
    "p23 = performance(weights_23, y_23, std_tx_23)\n",
    "print(\"0  Size: \", len(y_0), \"\\tPerformance: \", p0)\n",
    "print(\"1  Size: \", len(y_1), \"\\tPerformance: \", p1)\n",
    "print(\"23 Size: \", len(y_23), \"\\tPerformance: \", p23)\n",
    "print(\"Overall: \", (p0 * len(y_0) + len(y_1) * p1 + p23 * len(y_23)) / len(y))\n",
    "print(\"******* \")\n",
    "\n",
    "\n",
    "print(\"WITH additional feature\")\n",
    "\n",
    "# Add the feature\n",
    "std_tx_0 = add_feature(std_tx_0)\n",
    "std_tx_1 = add_feature(std_tx_1)\n",
    "std_tx_23 = add_feature(std_tx_23)\n",
    "\n",
    "weights_0 = least_squares(y_0, std_tx_0)\n",
    "weights_1 = least_squares(y_1, std_tx_1)\n",
    "weights_23 = least_squares(y_23, std_tx_23)\n",
    "\n",
    "p0 = performance(weights_0, y_0, std_tx_0)\n",
    "p1 = performance(weights_1, y_1, std_tx_1)\n",
    "p23 = performance(weights_23, y_23, std_tx_23)\n",
    "print(\"0  Size: \", len(y_0), \"\\tPerformance: \", p0)\n",
    "print(\"1  Size: \", len(y_1), \"\\tPerformance: \", p1)\n",
    "print(\"23 Size: \", len(y_23), \"\\tPerformance: \", p23)\n",
    "print(\"Overall: \", (p0 * len(y_0) + len(y_1) * p1 + p23 * len(y_23)) / len(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load test data\n",
    "DATA_TEST_PATH = '../../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "i_0_test, i_1_test, i_23_test = split_dataset_wrt22(tX_test)\n",
    "\n",
    "# split tx into 3 set \n",
    "tx_0_test = tX_test[i_0_test]\n",
    "tx_1_test = tX_test[i_1_test]\n",
    "tx_23_test = tX_test[i_23_test]\n",
    "\n",
    "# standardize\n",
    "std_tx_0_test = standardize_0(tx_0_test)\n",
    "std_tx_1_test = standardize_1(tx_1_test)\n",
    "std_tx_23_test = standardize_23(tx_23_test)\n",
    "\n",
    "# add feature\n",
    "std_tx_0_test = add_feature(std_tx_0_test)\n",
    "std_tx_1_test = add_feature(std_tx_1_test)\n",
    "std_tx_23_test = add_feature(std_tx_23_test)\n",
    "\n",
    "# split index into 3 features\n",
    "ids_0_test = ids_test[i_0_test]\n",
    "ids_1_test = ids_test[i_1_test]\n",
    "ids_23_test = ids_test[i_23_test]\n",
    "\n",
    "# Make prediction\n",
    "y_pred_0 = predict_labels(weights_0, std_tx_0_test)\n",
    "y_pred_1 = predict_labels(weights_1, std_tx_1_test)\n",
    "y_pred_23 = predict_labels(weights_23, std_tx_23_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate everything into one\n",
    "y_pred = np.concatenate((y_pred_0, y_pred_1, y_pred_23), axis=0)\n",
    "ids_test = np.concatenate((ids_0_test, ids_1_test, ids_23_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output to file\n",
    "OUTPUT_PATH = '../../data/output.csv' # TODO: fill in desired name of output file for submission\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
