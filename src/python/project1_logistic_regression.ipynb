{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from logistic_regression import *\n",
    "from helpers import *\n",
    "from costs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14187.56452566]\n",
      " [-20848.53205722]\n",
      " [  -833.83185996]\n",
      " [ 11421.66201088]\n",
      " [  8403.17614897]\n",
      " [ 11376.56059522]\n",
      " [  8338.41723459]\n",
      " [   726.46556678]\n",
      " [  -906.92957136]\n",
      " [  9090.75159575]\n",
      " [-11592.01831993]\n",
      " [ 16121.73313427]\n",
      " [  8385.37835498]\n",
      " [ 13955.53882204]\n",
      " [   -55.95855309]\n",
      " [  -261.18146666]\n",
      " [ -1895.29682131]\n",
      " [    89.95095961]\n",
      " [   244.74297271]\n",
      " [  1332.78509222]\n",
      " [   443.47613404]\n",
      " [  8039.76595952]\n",
      " [  7922.82778687]\n",
      " [  9349.89669626]\n",
      " [  8926.61821419]\n",
      " [  8926.54570359]\n",
      " [  8347.90727758]\n",
      " [  8380.56857542]\n",
      " [  8380.02116578]\n",
      " [  7967.12019039]]\n",
      "Performance:  0.638892\n",
      "Iteration:  0\n",
      "Current iteration=0, the loss=173286.79513998624\n",
      "Current iteration=100, the loss=8044929437.424736\n",
      "Current iteration=200, the loss=10364511317.089073\n",
      "[[  3.10413540e+03]\n",
      " [ -7.97799171e+04]\n",
      " [ -1.12701100e+05]\n",
      " [  8.25174934e+04]\n",
      " [ -7.81261838e+03]\n",
      " [  3.40100627e+05]\n",
      " [ -1.39064469e+04]\n",
      " [  8.87329271e+04]\n",
      " [ -1.83529271e+03]\n",
      " [ -2.79047885e+04]\n",
      " [ -5.91904383e+04]\n",
      " [  2.74985043e+04]\n",
      " [ -9.24351597e+03]\n",
      " [  9.50350187e+04]\n",
      " [ -5.84937509e+02]\n",
      " [  5.54080231e+01]\n",
      " [  1.13627550e+05]\n",
      " [  1.06478313e+03]\n",
      " [  7.23420676e+02]\n",
      " [  4.56715903e+04]\n",
      " [  5.22596495e+02]\n",
      " [ -8.81949125e+03]\n",
      " [ -1.08072963e+05]\n",
      " [  3.81633930e+04]\n",
      " [  4.45594075e+04]\n",
      " [  4.45726063e+04]\n",
      " [ -5.09862916e+03]\n",
      " [ -9.92575307e+03]\n",
      " [ -1.01142748e+04]\n",
      " [ -8.02510060e+04]]\n",
      "Performance:  0.7218439999999999\n",
      "Iteration:  80\n",
      "Current iteration=300, the loss=11622101525.856266\n",
      "Current iteration=400, the loss=12238664701.983198\n",
      "Current iteration=500, the loss=12609539419.609898\n",
      "[[  8.17760801e+02]\n",
      " [ -8.14344658e+04]\n",
      " [ -1.10741885e+05]\n",
      " [  8.14295544e+04]\n",
      " [ -1.52139189e+04]\n",
      " [  4.20214320e+05]\n",
      " [ -2.18721980e+04]\n",
      " [  8.50727269e+04]\n",
      " [  8.67329564e+02]\n",
      " [ -3.03975786e+04]\n",
      " [ -5.96168359e+04]\n",
      " [  2.99691849e+04]\n",
      " [ -1.63878345e+04]\n",
      " [  9.52267084e+04]\n",
      " [ -4.91646197e+02]\n",
      " [  2.10022067e+02]\n",
      " [  1.15793932e+05]\n",
      " [  9.78521264e+02]\n",
      " [  7.55437754e+02]\n",
      " [  4.72117903e+04]\n",
      " [  5.43832777e+02]\n",
      " [ -3.64421971e+03]\n",
      " [ -1.39737038e+05]\n",
      " [  4.50674663e+04]\n",
      " [  5.48068198e+04]\n",
      " [  5.48827946e+04]\n",
      " [ -5.89546833e+03]\n",
      " [ -1.74371604e+04]\n",
      " [ -1.78629890e+04]\n",
      " [ -8.37250688e+04]]\n",
      "Performance:  0.7218439999999999\n",
      "Iteration:  80\n",
      "Current iteration=600, the loss=12805813845.28596\n",
      "Current iteration=700, the loss=12974753552.395021\n",
      "Current iteration=800, the loss=13113450885.672749\n",
      "[[  1.13248517e+03]\n",
      " [ -8.21656328e+04]\n",
      " [ -1.07764411e+05]\n",
      " [  7.89896398e+04]\n",
      " [ -1.98568728e+04]\n",
      " [  4.54253240e+05]\n",
      " [ -2.60394759e+04]\n",
      " [  8.17625011e+04]\n",
      " [  1.90018020e+03]\n",
      " [ -3.05173268e+04]\n",
      " [ -5.63151860e+04]\n",
      " [  3.10656440e+04]\n",
      " [ -2.04432257e+04]\n",
      " [  9.71304544e+04]\n",
      " [ -3.77624070e+02]\n",
      " [  2.39185561e+02]\n",
      " [  1.13298767e+05]\n",
      " [  9.60464968e+02]\n",
      " [  8.02453073e+02]\n",
      " [  4.89209879e+04]\n",
      " [  5.59521946e+02]\n",
      " [ -2.11316007e+03]\n",
      " [ -1.47082608e+05]\n",
      " [  4.51730940e+04]\n",
      " [  5.91869703e+04]\n",
      " [  5.93207973e+04]\n",
      " [ -4.69897125e+03]\n",
      " [ -2.17935275e+04]\n",
      " [ -2.24572084e+04]\n",
      " [ -8.37398785e+04]]\n",
      "Performance:  0.7218439999999999\n",
      "Iteration:  80\n",
      "Current iteration=900, the loss=13275315902.430742\n",
      "Current iteration=1000, the loss=13297069248.740763\n",
      "Current iteration=1100, the loss=13328958089.248669\n",
      "[[  1.20882675e+03]\n",
      " [ -8.21688369e+04]\n",
      " [ -1.06494974e+05]\n",
      " [  7.82193477e+04]\n",
      " [ -2.33152375e+04]\n",
      " [  4.70113920e+05]\n",
      " [ -2.86341006e+04]\n",
      " [  8.04050646e+04]\n",
      " [  2.10207189e+03]\n",
      " [ -3.10251994e+04]\n",
      " [ -5.47516044e+04]\n",
      " [  3.12683510e+04]\n",
      " [ -2.31876126e+04]\n",
      " [  9.78114313e+04]\n",
      " [ -3.62873653e+02]\n",
      " [  2.56327478e+02]\n",
      " [  1.12112687e+05]\n",
      " [  9.50339374e+02]\n",
      " [  8.01343866e+02]\n",
      " [  4.94491378e+04]\n",
      " [  5.92750259e+02]\n",
      " [ -1.64938197e+03]\n",
      " [ -1.47552621e+05]\n",
      " [  4.26179357e+04]\n",
      " [  6.11401978e+04]\n",
      " [  6.13264279e+04]\n",
      " [ -2.81994017e+03]\n",
      " [ -2.48104586e+04]\n",
      " [ -2.57126587e+04]\n",
      " [ -8.42279910e+04]]\n",
      "Performance:  0.7218439999999999\n",
      "Iteration:  80\n",
      "Current iteration=1200, the loss=13359549011.879\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-93f5e1438f49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgammas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# err = compute_loss(y, tX, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# struct[(gamma, lambda_)] = (w, err)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chenfs/Google Drive/EPFL/Courses/PC and ML/ML_course_origin/ML_course/projects/project1/src/python/logistic_regression.py\u001b[0m in \u001b[0;36mreg_logistic_regression\u001b[0;34m(y, tx, lambda_, gamma, max_iters)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreg_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;34m\"\"\" return the final w from the penalized logistic regression, with lambda_ as a non 0 value\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlogistic_regression_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/chenfs/Google Drive/EPFL/Courses/PC and ML/ML_course_origin/ML_course/projects/project1/src/python/logistic_regression.py\u001b[0m in \u001b[0;36mlogistic_regression_helper\u001b[0;34m(y, tx, gamma, max_iters, lambda_)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gradient_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chenfs/Google Drive/EPFL/Courses/PC and ML/ML_course_origin/ML_course/projects/project1/src/python/logistic_regression.py\u001b[0m in \u001b[0;36mcalculate_loss_logistic_regression\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mover_700\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprediction_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprediction_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mover_700\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mover_700\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprediction_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# There are two parameters, lambda_ and gamma, where gamma is the step size \n",
    "\n",
    "max_iter = 20000\n",
    "lambdas = np.arange(0.1, 0.4, 0.1)\n",
    "gammas = [0.5]\n",
    "\n",
    "# When lambda is 0, reg_logistic_regression is naive non-penalized logistic_regression.\n",
    "\n",
    "tx, _, std_x = standardize(tX)\n",
    "\n",
    "weights = reg_logistic_regression(y, tx, lambdas[0], gammas[0], max_iter)\n",
    "# err = compute_loss(y, tX, w)\n",
    "# struct[(gamma, lambda_)] = (w, err)\n",
    "# #         break\n",
    "print(weights)\n",
    "# for (gamma, lambda_), (w, err) in struct.items():\n",
    "#     print(\"Gamma: \", gamma, \" Lamdba: \", lambda_, \" w: \", w, \"error: \", err)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n",
      "0.719484\n"
     ]
    }
   ],
   "source": [
    "weights =      [  3264.41428568,\n",
    "  -103498.43040039,\n",
    "   -27944.48648106,\n",
    "   -36731.0555926 ,\n",
    "   -82923.2716588 ,\n",
    "     2761.63293809,\n",
    "   -24230.40255878,\n",
    "   409836.06933039,\n",
    "    14829.8163511 ,\n",
    "    38230.32931558,\n",
    "  -284541.39042936,\n",
    "   662654.74622621,\n",
    "    80791.09716388,\n",
    "    65926.74105577,\n",
    "    -1032.49192099,\n",
    "   -17500.88986746,\n",
    "    24786.4442881 ,\n",
    "    -7594.73927   ,\n",
    "    14068.93010338,\n",
    "    42981.56765674,\n",
    "     6275.32816837,\n",
    "    -6455.53314786,\n",
    "  -164153.32220581,\n",
    "    13395.30580001,\n",
    "   -10880.4029573 ,\n",
    "     1141.95701937,\n",
    "     1170.96908066,\n",
    "    12837.31514973,\n",
    "    10274.84678099,\n",
    "   -52489.01936993]\n",
    "compare_pred = predict_labels(weights, tX) - y\n",
    "print(compare_pred.shape)\n",
    "\n",
    "nonzero = 0\n",
    "for i in range(len(compare_pred)):\n",
    "    if (compare_pred[i] != 0):\n",
    "        nonzero += 1\n",
    "\n",
    "print(1 - nonzero / compare_pred.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../../data/output.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
