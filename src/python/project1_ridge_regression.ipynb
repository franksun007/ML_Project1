{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the training data\n",
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Constant to indicate +1 and 0 for classification\n",
    "BINARY_CLASSIFICATOIN_0 = -1\n",
    "BINARY_CLASSIFICATOIN_1 = 1\n",
    "\n",
    "\n",
    "def ridge_regression(y, tx, lambda_):\n",
    "    i = np.eye(tx.shape[1])\n",
    "    i[0][0] = 0  # Because we don't need to penalize the first term\n",
    "    return np.linalg.solve(tx.T @ tx + lambda_ * i, tx.T @ y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(weights, y, xT):\n",
    "    \"\"\"Returns the percentage of successful classifications for the weights,\n",
    "    given the expected results (y) and data (xT)\"\"\"\n",
    "    from proj1_helpers import predict_labels\n",
    "    compare_pred = predict_labels(weights, xT).reshape((len(y), 1))\n",
    "#     print(compare_pred.shape)\n",
    "#     print(y.reshape((len(y), 1)))\n",
    "    compare_pred -= y.reshape((len(y), 1))\n",
    "#     print(compare_pred.shape)\n",
    "\n",
    "    non_zero = 0\n",
    "    for i in range(len(compare_pred)):\n",
    "        if compare_pred[i] != 0:\n",
    "            non_zero += 1\n",
    "            \n",
    "    return 1 - non_zero / compare_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def standardize_0123_helper(x):\n",
    "    \"\"\"\n",
    "    Helper function that standardize the input data to mean 0 stddev 1. \n",
    "    The function replace all the -999 entries with the mean of all non -999\n",
    "    entries. \n",
    "    \"\"\"\n",
    "    for i in range(x.shape[1]):\n",
    "        mean = np.mean(x[np.where(x[:, i] != -999), i])\n",
    "        x[np.where(x[:, i] == -999), i] = mean \n",
    "        x[np.where(x[:, i] != -999), i] = x[np.where(x[:, i] != -999), i] - mean\n",
    "    \n",
    "    std_x = np.std(x, axis=0)\n",
    "    x[:, std_x > 0] = x[:, std_x > 0] / std_x[std_x > 0]\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def standardize_0(x):\n",
    "    \"\"\"\n",
    "    Standardize function for PRI_jet_num is 0\n",
    "    Return a standardize version of the original feature, with\n",
    "    uselessful thrown away\n",
    "    \"\"\"\n",
    "    # the features left that are meaningful and useful for training\n",
    "    feature_left = np.array([0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21])\n",
    "    left_x = np.zeros((x.shape[0], len(feature_left)))\n",
    "    left_x[:, :] = x[:, feature_left]\n",
    "    return standardize_0123_helper(left_x)\n",
    "    \n",
    "\n",
    "def standardize_1(x):\n",
    "    \"\"\"\n",
    "    Standardize function for PRI_jet_num is 1\n",
    "    Return a standardize version of the original feature, with\n",
    "    uselessful thrown away\n",
    "    \"\"\"\n",
    "    # the features left that are meaningful and useful for training\n",
    "    feature_left = np.array([0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 29])\n",
    "    left_x = np.zeros((x.shape[0], len(feature_left)))\n",
    "    left_x[:, :] = x[:, feature_left]\n",
    "    return standardize_0123_helper(left_x)\n",
    "    \n",
    "    \n",
    "def standardize_23(x):\n",
    "    \"\"\"\n",
    "    Standardize function for PRI_jet_num is 2 or 3\n",
    "    Return a standardize version of the original feature, with\n",
    "    uselessful thrown away\n",
    "    \"\"\"\n",
    "    # the features left that are meaningful and useful for training\n",
    "    feature_left = np.delete(np.arange(30), 22)\n",
    "    left_x = np.zeros((x.shape[0], len(feature_left)))\n",
    "    left_x[:, :] = x[:, feature_left]\n",
    "    return standardize_0123_helper(left_x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The column index for PRI_jet_num\n",
    "jet_num_col = 22\n",
    "\n",
    "def split_dataset_wrt22(x):\n",
    "    \"\"\"\n",
    "    Return three tuples of indices that splits x with respect to\n",
    "    feature 22 - PRI_jet_num.\n",
    "    First  Tuple of indicies: index in x where PRI_jet_num is 0\n",
    "    Second Tuple of indicies: index in x where PRI_jet_num is 1\n",
    "    Third  Tuple of indicies: index in x where PRI_jet_num is 2 or 3\n",
    "    \"\"\"\n",
    "    x_22_0 = np.where(x[:, jet_num_col] == 0)\n",
    "    x_22_1 = np.where(x[:, jet_num_col] == 1)\n",
    "    x_22_23 = np.where(x[:, jet_num_col] >= 2)\n",
    "    return x_22_0, x_22_1, x_22_23\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_poly(x, degree):\n",
    "    \"\"\"\n",
    "    Build the polynomial rising to the pass in parameter degree. \n",
    "    Return a matrix that has the same entry as pass in x, while \n",
    "    more features added accroding to degree. \n",
    "    Each individual feature is a some power of the original feature.\n",
    "    \"\"\"\n",
    "    matrix = np.zeros((x.shape[0], x.shape[1] * (degree + 1)))\n",
    "    for i in range(degree + 1):\n",
    "        matrix[:, (i * x.shape[1]) : ((i + 1) * x.shape[1])] = (x ** i)[:]\n",
    "        \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_feature_helper(x, op, ori_shape):\n",
    "    \"\"\"\n",
    "    Helper function that takes in x, an operator op, and the\n",
    "    original shape of x. \n",
    "    Return a matrix that is expanded with the feature added.\n",
    "    The matrix will have the same entries as x, but additional\n",
    "    ori_shape columns of feature added. \n",
    "    \"\"\"\n",
    "    matrix = np.zeros((x.shape[0], x.shape[1] + ori_shape))\n",
    "    matrix[:, : x.shape[1]] = x[:, :]\n",
    "    matrix[:, x.shape[1] : ] = op(x[:, : ori_shape])\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def add_feature(x):\n",
    "    \"\"\"\n",
    "    Add some features that we consider as useful and meaningful\n",
    "    to the data and good for training. \n",
    "    Return a modified x with features added. \n",
    "    \"\"\"\n",
    "    original_d = x.shape[1]\n",
    "    x = add_feature_helper(x, np.sin, original_d)\n",
    "    x = add_feature_helper(x, np.tanh, original_d)\n",
    "#     x = add_feature_helper(x, np.sin, original_d)\n",
    "    return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree:  2 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.8258584968922963\n",
      "1  Size:  77544 \tPerformance:  0.756009491385536\n",
      "23 Size:  72543 \tPerformance:  0.7698054946721256\n",
      "Overall:  0.787928\n",
      "******* \n",
      "Degree:  3 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.8297518841392011\n",
      "1  Size:  77544 \tPerformance:  0.7657072113896626\n",
      "23 Size:  72543 \tPerformance:  0.7918338089133341\n",
      "Overall:  0.798884\n",
      "******* \n",
      "Degree:  4 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.8326143745058201\n",
      "1  Size:  77544 \tPerformance:  0.7764623955431755\n",
      "23 Size:  72543 \tPerformance:  0.8025584825551741\n",
      "Overall:  0.806476\n",
      "******* \n",
      "Degree:  5 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.8367379620269635\n",
      "1  Size:  77544 \tPerformance:  0.7803698545341999\n",
      "23 Size:  72543 \tPerformance:  0.8042678135726397\n",
      "Overall:  0.809832\n",
      "******* \n",
      "Degree:  6 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.838899842863291\n",
      "1  Size:  77544 \tPerformance:  0.7845997111317445\n",
      "23 Size:  72543 \tPerformance:  0.8058392953145032\n",
      "Overall:  0.812464\n",
      "******* \n",
      "Degree:  7 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.8405112447829612\n",
      "1  Size:  77544 \tPerformance:  0.7919245847518828\n",
      "23 Size:  72543 \tPerformance:  0.8147719283735164\n",
      "Overall:  0.817972\n",
      "******* \n",
      "Degree:  8 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.8425930559586841\n",
      "1  Size:  77544 \tPerformance:  0.7992623542762819\n",
      "23 Size:  72543 \tPerformance:  0.8247246460719849\n",
      "Overall:  0.823968\n",
      "******* \n",
      "Degree:  9 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.8432035871207951\n",
      "1  Size:  77544 \tPerformance:  0.802989270607655\n",
      "23 Size:  72543 \tPerformance:  0.8290944681085701\n",
      "Overall:  0.826636\n",
      "******* \n",
      "Degree:  10 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.8403310880466005\n",
      "1  Size:  77544 \tPerformance:  0.8032471886928712\n",
      "23 Size:  72543 \tPerformance:  0.8293701666597741\n",
      "Overall:  0.825648\n",
      "******* \n",
      "Degree:  11 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.5250267732927647\n",
      "1  Size:  77544 \tPerformance:  0.8044336118848654\n",
      "23 Size:  72543 \tPerformance:  0.8301834773858263\n",
      "Overall:  0.70024\n",
      "******* \n",
      "Degree:  12 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.79059782010349\n",
      "1  Size:  77544 \tPerformance:  0.8057618900237284\n",
      "23 Size:  72543 \tPerformance:  0.8315895399969673\n",
      "Overall:  0.807196\n",
      "******* \n",
      "Degree:  13 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.7803689209612363\n",
      "1  Size:  77544 \tPerformance:  0.7692535850613845\n",
      "23 Size:  72543 \tPerformance:  0.8329818176805481\n",
      "Overall:  0.792188\n",
      "******* \n",
      "Degree:  14 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.7695595167795982\n",
      "1  Size:  77544 \tPerformance:  0.8030021665119158\n",
      "23 Size:  72543 \tPerformance:  0.7777869677294846\n",
      "Overall:  0.78232\n",
      "******* \n",
      "Degree:  15 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.664057730225296\n",
      "1  Size:  77544 \tPerformance:  0.7764366037346538\n",
      "23 Size:  72543 \tPerformance:  0.5331872131011952\n",
      "Overall:  0.66094\n",
      "******* \n",
      "Degree:  16 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.6870977750643059\n",
      "1  Size:  77544 \tPerformance:  0.6643325079954606\n",
      "23 Size:  72543 \tPerformance:  0.5511765435672635\n",
      "Overall:  0.640596\n",
      "******* \n",
      "Degree:  17 \tLambda:  1e-05\n",
      "0  Size:  99913 \tPerformance:  0.6360433577212175\n",
      "1  Size:  77544 \tPerformance:  0.5374754977819045\n",
      "23 Size:  72543 \tPerformance:  0.7324621259115283\n",
      "Overall:  0.633448\n",
      "******* \n",
      "Degree:  2 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.8258484881847207\n",
      "1  Size:  77544 \tPerformance:  0.7560610750025791\n",
      "23 Size:  72543 \tPerformance:  0.7698192795996857\n",
      "Overall:  0.787944\n",
      "******* \n",
      "Degree:  3 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.8297418754316255\n",
      "1  Size:  77544 \tPerformance:  0.7657072113896626\n",
      "23 Size:  72543 \tPerformance:  0.791820023985774\n",
      "Overall:  0.798876\n",
      "******* \n",
      "Degree:  4 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.8326043657982445\n",
      "1  Size:  77544 \tPerformance:  0.7764494996389146\n",
      "23 Size:  72543 \tPerformance:  0.8025722674827344\n",
      "Overall:  0.806472\n",
      "******* \n",
      "Degree:  5 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.8367179446118123\n",
      "1  Size:  77544 \tPerformance:  0.7804085422469824\n",
      "23 Size:  72543 \tPerformance:  0.8042540286450794\n",
      "Overall:  0.809832\n",
      "******* \n",
      "Degree:  6 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.8389498864011691\n",
      "1  Size:  77544 \tPerformance:  0.7845868152274837\n",
      "23 Size:  72543 \tPerformance:  0.8058530802420634\n",
      "Overall:  0.812484\n",
      "******* \n",
      "Degree:  7 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.840541270905688\n",
      "1  Size:  77544 \tPerformance:  0.7919632724646652\n",
      "23 Size:  72543 \tPerformance:  0.8147719283735164\n",
      "Overall:  0.817996\n",
      "******* \n",
      "Degree:  8 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.8424729514677769\n",
      "1  Size:  77544 \tPerformance:  0.7991591870421955\n",
      "23 Size:  72543 \tPerformance:  0.8247246460719849\n",
      "Overall:  0.823888\n",
      "******* \n",
      "Degree:  9 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.8432135958283706\n",
      "1  Size:  77544 \tPerformance:  0.8029763747033942\n",
      "23 Size:  72543 \tPerformance:  0.8290806831810099\n",
      "Overall:  0.826632\n",
      "******* \n",
      "Degree:  10 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.8407714711799266\n",
      "1  Size:  77544 \tPerformance:  0.8031956050758279\n",
      "23 Size:  72543 \tPerformance:  0.8294115214424548\n",
      "Overall:  0.82582\n",
      "******* \n",
      "Degree:  11 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.8359773002512185\n",
      "1  Size:  77544 \tPerformance:  0.804459403693387\n",
      "23 Size:  72543 \tPerformance:  0.8302386170960672\n",
      "Overall:  0.824536\n",
      "******* \n",
      "Degree:  12 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.6992083112307708\n",
      "1  Size:  77544 \tPerformance:  0.8050397193851233\n",
      "23 Size:  72543 \tPerformance:  0.8305281005748315\n",
      "Overall:  0.77014\n",
      "******* \n",
      "Degree:  13 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.8056108814668762\n",
      "1  Size:  77544 \tPerformance:  0.7603940988342103\n",
      "23 Size:  72543 \tPerformance:  0.8254138924499952\n",
      "Overall:  0.797332\n",
      "******* \n",
      "Degree:  14 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.7697296648083833\n",
      "1  Size:  77544 \tPerformance:  0.8003585061384504\n",
      "23 Size:  72543 \tPerformance:  0.8020897950181272\n",
      "Overall:  0.78862\n",
      "******* \n",
      "Degree:  15 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.5950276740764465\n",
      "1  Size:  77544 \tPerformance:  0.6330986278757866\n",
      "23 Size:  72543 \tPerformance:  0.5148256895910013\n",
      "Overall:  0.583564\n",
      "******* \n",
      "Degree:  16 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.719405883118313\n",
      "1  Size:  77544 \tPerformance:  0.7973408645414216\n",
      "23 Size:  72543 \tPerformance:  0.5270667052644638\n",
      "Overall:  0.687768\n",
      "******* \n",
      "Degree:  17 \tLambda:  2.27584592607e-05\n",
      "0  Size:  99913 \tPerformance:  0.7883858957292844\n",
      "1  Size:  77544 \tPerformance:  0.7690085628804292\n",
      "23 Size:  72543 \tPerformance:  0.7468673752119432\n",
      "Overall:  0.770328\n",
      "******* \n",
      "Degree:  2 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.8258084533544183\n",
      "1  Size:  77544 \tPerformance:  0.7561642422366657\n",
      "23 Size:  72543 \tPerformance:  0.7698192795996857\n",
      "Overall:  0.78796\n",
      "******* \n",
      "Degree:  3 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.8297418754316255\n",
      "1  Size:  77544 \tPerformance:  0.7656943154854019\n",
      "23 Size:  72543 \tPerformance:  0.7918338089133341\n",
      "Overall:  0.798876\n",
      "******* \n",
      "Degree:  4 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.8326043657982445\n",
      "1  Size:  77544 \tPerformance:  0.7764881873516971\n",
      "23 Size:  72543 \tPerformance:  0.8025860524102946\n",
      "Overall:  0.806488\n",
      "******* \n",
      "Degree:  5 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.8367379620269635\n",
      "1  Size:  77544 \tPerformance:  0.7803698545341999\n",
      "23 Size:  72543 \tPerformance:  0.804226458789959\n",
      "Overall:  0.80982\n",
      "******* \n",
      "Degree:  6 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.8388598080329888\n",
      "1  Size:  77544 \tPerformance:  0.7845868152274837\n",
      "23 Size:  72543 \tPerformance:  0.8058530802420634\n",
      "Overall:  0.812448\n",
      "******* \n",
      "Degree:  7 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.8403811315844785\n",
      "1  Size:  77544 \tPerformance:  0.7919374806561437\n",
      "23 Size:  72543 \tPerformance:  0.8147857133010766\n",
      "Overall:  0.817928\n",
      "******* \n",
      "Degree:  8 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.8425830472511084\n",
      "1  Size:  77544 \tPerformance:  0.7992236665634994\n",
      "23 Size:  72543 \tPerformance:  0.8247384309995451\n",
      "Overall:  0.823956\n",
      "******* \n",
      "Degree:  9 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.8432135958283706\n",
      "1  Size:  77544 \tPerformance:  0.8029634787991334\n",
      "23 Size:  72543 \tPerformance:  0.8290668982534497\n",
      "Overall:  0.826624\n",
      "******* \n",
      "Degree:  10 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.8395704262708557\n",
      "1  Size:  77544 \tPerformance:  0.8031956050758279\n",
      "23 Size:  72543 \tPerformance:  0.8293839515873345\n",
      "Overall:  0.825332\n",
      "******* \n",
      "Degree:  11 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.724390219490957\n",
      "1  Size:  77544 \tPerformance:  0.8044078200763438\n",
      "23 Size:  72543 \tPerformance:  0.8301145527480254\n",
      "Overall:  0.779888\n",
      "******* \n",
      "Degree:  12 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.7678580364917478\n",
      "1  Size:  77544 \tPerformance:  0.8031956050758279\n",
      "23 Size:  72543 \tPerformance:  0.8320306576788938\n",
      "Overall:  0.79744\n",
      "******* \n",
      "Degree:  13 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.8119163672394983\n",
      "1  Size:  77544 \tPerformance:  0.80099040544723\n",
      "23 Size:  72543 \tPerformance:  0.8324442055057001\n",
      "Overall:  0.814484\n",
      "******* \n",
      "Degree:  14 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.7469698637814899\n",
      "1  Size:  77544 \tPerformance:  0.8028474156607861\n",
      "23 Size:  72543 \tPerformance:  0.8275367712942668\n",
      "Overall:  0.78768\n",
      "******* \n",
      "Degree:  15 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.6478536326604145\n",
      "1  Size:  77544 \tPerformance:  0.7656298359640978\n",
      "23 Size:  72543 \tPerformance:  0.5045972733413286\n",
      "Overall:  0.642816\n",
      "******* \n",
      "Degree:  16 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.7129202406093301\n",
      "1  Size:  77544 \tPerformance:  0.8028345197565253\n",
      "23 Size:  72543 \tPerformance:  0.5996581337965069\n",
      "Overall:  0.707944\n",
      "******* \n",
      "Degree:  17 \tLambda:  5.17947467923e-05\n",
      "0  Size:  99913 \tPerformance:  0.7746739663507252\n",
      "1  Size:  77544 \tPerformance:  0.764752914474363\n",
      "23 Size:  72543 \tPerformance:  0.5564975256055029\n",
      "Overall:  0.708288\n",
      "******* \n",
      "Degree:  2 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.8257884359392671\n",
      "1  Size:  77544 \tPerformance:  0.756138450428144\n",
      "23 Size:  72543 \tPerformance:  0.7698192795996857\n",
      "Overall:  0.787944\n",
      "******* \n",
      "Degree:  3 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.8297418754316255\n",
      "1  Size:  77544 \tPerformance:  0.7656943154854019\n",
      "23 Size:  72543 \tPerformance:  0.7917648842755332\n",
      "Overall:  0.798856\n",
      "******* \n",
      "Degree:  4 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.8325443135527909\n",
      "1  Size:  77544 \tPerformance:  0.7764752914474363\n",
      "23 Size:  72543 \tPerformance:  0.8025722674827344\n",
      "Overall:  0.806456\n",
      "******* \n",
      "Degree:  5 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.8367479707345391\n",
      "1  Size:  77544 \tPerformance:  0.7803569586299391\n",
      "23 Size:  72543 \tPerformance:  0.8041851040072785\n",
      "Overall:  0.809808\n",
      "******* \n",
      "Degree:  6 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.8389598951087446\n",
      "1  Size:  77544 \tPerformance:  0.7845868152274837\n",
      "23 Size:  72543 \tPerformance:  0.8058806500971838\n",
      "Overall:  0.812496\n",
      "******* \n",
      "Degree:  7 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.8401609400178155\n",
      "1  Size:  77544 \tPerformance:  0.7919503765604045\n",
      "23 Size:  72543 \tPerformance:  0.8147305735908358\n",
      "Overall:  0.817828\n",
      "******* \n",
      "Degree:  8 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.8426230820814108\n",
      "1  Size:  77544 \tPerformance:  0.7991720829464561\n",
      "23 Size:  72543 \tPerformance:  0.8247522159271052\n",
      "Overall:  0.82396\n",
      "******* \n",
      "Degree:  9 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.8432236045359462\n",
      "1  Size:  77544 \tPerformance:  0.8029763747033942\n",
      "23 Size:  72543 \tPerformance:  0.8290255434707691\n",
      "Overall:  0.82662\n",
      "******* \n",
      "Degree:  10 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.8381892246254241\n",
      "1  Size:  77544 \tPerformance:  0.8031698132673063\n",
      "23 Size:  72543 \tPerformance:  0.8293977365148946\n",
      "Overall:  0.824776\n",
      "******* \n",
      "Degree:  11 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.674867134406934\n",
      "1  Size:  77544 \tPerformance:  0.804459403693387\n",
      "23 Size:  72543 \tPerformance:  0.8301696924582661\n",
      "Overall:  0.760128\n",
      "******* \n",
      "Degree:  12 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.6128631909761493\n",
      "1  Size:  77544 \tPerformance:  0.7959481068812545\n",
      "23 Size:  72543 \tPerformance:  0.8315206153591663\n",
      "Overall:  0.7331\n",
      "******* \n",
      "Degree:  13 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.7989650996366839\n",
      "1  Size:  77544 \tPerformance:  0.8037114412462601\n",
      "23 Size:  72543 \tPerformance:  0.8327336889844644\n",
      "Overall:  0.810236\n",
      "******* \n",
      "Degree:  14 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.7416652487664268\n",
      "1  Size:  77544 \tPerformance:  0.8028216238522645\n",
      "23 Size:  72543 \tPerformance:  0.5286244020787672\n",
      "Overall:  0.698816\n",
      "******* \n",
      "Degree:  15 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.7624533344009288\n",
      "1  Size:  77544 \tPerformance:  0.7697049417105127\n",
      "23 Size:  72543 \tPerformance:  0.5087878913196311\n",
      "Overall:  0.691096\n",
      "******* \n",
      "Degree:  16 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.7059141453064166\n",
      "1  Size:  77544 \tPerformance:  0.7890230062932013\n",
      "23 Size:  72543 \tPerformance:  0.5213046055442978\n",
      "Overall:  0.678124\n",
      "******* \n",
      "Degree:  17 \tLambda:  0.000117876863479\n",
      "0  Size:  99913 \tPerformance:  0.7867244502717364\n",
      "1  Size:  77544 \tPerformance:  0.656775508098628\n",
      "23 Size:  72543 \tPerformance:  0.5527342403815668\n",
      "Overall:  0.67852\n",
      "******* \n",
      "Degree:  2 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.8257884359392671\n",
      "1  Size:  77544 \tPerformance:  0.756138450428144\n",
      "23 Size:  72543 \tPerformance:  0.7697779248170051\n",
      "Overall:  0.787932\n",
      "******* \n",
      "Degree:  3 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.8297518841392011\n",
      "1  Size:  77544 \tPerformance:  0.765681419581141\n",
      "23 Size:  72543 \tPerformance:  0.7917373144204127\n",
      "Overall:  0.798848\n",
      "******* \n",
      "Degree:  4 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.8325643309679421\n",
      "1  Size:  77544 \tPerformance:  0.7764752914474363\n",
      "23 Size:  72543 \tPerformance:  0.8025033428449333\n",
      "Overall:  0.806444\n",
      "******* \n",
      "Degree:  5 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.8367179446118123\n",
      "1  Size:  77544 \tPerformance:  0.7803827504384607\n",
      "23 Size:  72543 \tPerformance:  0.8041437492245979\n",
      "Overall:  0.809792\n",
      "******* \n",
      "Degree:  6 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.8389298689860178\n",
      "1  Size:  77544 \tPerformance:  0.7845868152274837\n",
      "23 Size:  72543 \tPerformance:  0.8058806500971838\n",
      "Overall:  0.812484\n",
      "******* \n",
      "Degree:  7 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.840541270905688\n",
      "1  Size:  77544 \tPerformance:  0.7919503765604045\n",
      "23 Size:  72543 \tPerformance:  0.8146754338805949\n",
      "Overall:  0.817964\n",
      "******* \n",
      "Degree:  8 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.8424829601753525\n",
      "1  Size:  77544 \tPerformance:  0.7992107706592386\n",
      "23 Size:  72543 \tPerformance:  0.8247797857822257\n",
      "Overall:  0.823924\n",
      "******* \n",
      "Degree:  9 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.8431835697056439\n",
      "1  Size:  77544 \tPerformance:  0.8029763747033942\n",
      "23 Size:  72543 \tPerformance:  0.8290531133258895\n",
      "Overall:  0.826612\n",
      "******* \n",
      "Degree:  10 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.8386095903435989\n",
      "1  Size:  77544 \tPerformance:  0.8031698132673063\n",
      "23 Size:  72543 \tPerformance:  0.8293839515873345\n",
      "Overall:  0.82494\n",
      "******* \n",
      "Degree:  11 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.6649685226146748\n",
      "1  Size:  77544 \tPerformance:  0.8044336118848654\n",
      "23 Size:  72543 \tPerformance:  0.830086982892905\n",
      "Overall:  0.75614\n",
      "******* \n",
      "Degree:  12 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.675797944211464\n",
      "1  Size:  77544 \tPerformance:  0.7992365624677602\n",
      "23 Size:  72543 \tPerformance:  0.8315481852142868\n",
      "Overall:  0.75928\n",
      "******* \n",
      "Degree:  13 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.8079729364547156\n",
      "1  Size:  77544 \tPerformance:  0.8028474156607861\n",
      "23 Size:  72543 \tPerformance:  0.8328163985498256\n",
      "Overall:  0.813592\n",
      "******* \n",
      "Degree:  14 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.7370912694043819\n",
      "1  Size:  77544 \tPerformance:  0.7823816155988859\n",
      "23 Size:  72543 \tPerformance:  0.8314792605764857\n",
      "Overall:  0.778528\n",
      "******* \n",
      "Degree:  15 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.7788976409476245\n",
      "1  Size:  77544 \tPerformance:  0.5211492829877231\n",
      "23 Size:  72543 \tPerformance:  0.5351033180320637\n",
      "Overall:  0.628208\n",
      "******* \n",
      "Degree:  16 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.6821234473992374\n",
      "1  Size:  77544 \tPerformance:  0.7021819870009285\n",
      "23 Size:  72543 \tPerformance:  0.5411962560136747\n",
      "Overall:  0.647452\n",
      "******* \n",
      "Degree:  17 \tLambda:  0.000268269579528\n",
      "0  Size:  99913 \tPerformance:  0.7955921651837098\n",
      "1  Size:  77544 \tPerformance:  0.7821494893221913\n",
      "23 Size:  72543 \tPerformance:  0.5594888548860676\n",
      "Overall:  0.722912\n",
      "******* \n",
      "Degree:  2 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.8257884359392671\n",
      "1  Size:  77544 \tPerformance:  0.756138450428144\n",
      "23 Size:  72543 \tPerformance:  0.7696952152516439\n",
      "Overall:  0.787908\n",
      "******* \n",
      "Degree:  3 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.8297618928467767\n",
      "1  Size:  77544 \tPerformance:  0.765681419581141\n",
      "23 Size:  72543 \tPerformance:  0.7917373144204127\n",
      "Overall:  0.798852\n",
      "******* \n",
      "Degree:  4 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.8325643309679421\n",
      "1  Size:  77544 \tPerformance:  0.7764752914474363\n",
      "23 Size:  72543 \tPerformance:  0.8025309127000537\n",
      "Overall:  0.806452\n",
      "******* \n",
      "Degree:  5 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.8367079359042366\n",
      "1  Size:  77544 \tPerformance:  0.7803698545341999\n",
      "23 Size:  72543 \tPerformance:  0.8042126738623989\n",
      "Overall:  0.809804\n",
      "******* \n",
      "Degree:  6 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.8389598951087446\n",
      "1  Size:  77544 \tPerformance:  0.7845868152274837\n",
      "23 Size:  72543 \tPerformance:  0.8058668651696235\n",
      "Overall:  0.812492\n",
      "******* \n",
      "Degree:  7 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.840541270905688\n",
      "1  Size:  77544 \tPerformance:  0.7919632724646652\n",
      "23 Size:  72543 \tPerformance:  0.8146065092427939\n",
      "Overall:  0.817948\n",
      "******* \n",
      "Degree:  8 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.8426330907889864\n",
      "1  Size:  77544 \tPerformance:  0.799184978850717\n",
      "23 Size:  72543 \tPerformance:  0.8247384309995451\n",
      "Overall:  0.823964\n",
      "******* \n",
      "Degree:  9 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.8431835697056439\n",
      "1  Size:  77544 \tPerformance:  0.8029505828948726\n",
      "23 Size:  72543 \tPerformance:  0.8290393283983293\n",
      "Overall:  0.8266\n",
      "******* \n",
      "Degree:  10 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.8381291723799705\n",
      "1  Size:  77544 \tPerformance:  0.8032342927886104\n",
      "23 Size:  72543 \tPerformance:  0.8294666611526956\n",
      "Overall:  0.824792\n",
      "******* \n",
      "Degree:  11 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.6712439822645702\n",
      "1  Size:  77544 \tPerformance:  0.8043433405550398\n",
      "23 Size:  72543 \tPerformance:  0.8301972623133865\n",
      "Overall:  0.758652\n",
      "******* \n",
      "Degree:  12 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.5809554312251659\n",
      "1  Size:  77544 \tPerformance:  0.542582275869184\n",
      "23 Size:  72543 \tPerformance:  0.8233185834608439\n",
      "Overall:  0.63938\n",
      "******* \n",
      "Degree:  13 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.804539949756288\n",
      "1  Size:  77544 \tPerformance:  0.7958836273599504\n",
      "23 Size:  72543 \tPerformance:  0.8323890657954592\n",
      "Overall:  0.809936\n",
      "******* \n",
      "Degree:  14 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.7411247785573449\n",
      "1  Size:  77544 \tPerformance:  0.8035051067780873\n",
      "23 Size:  72543 \tPerformance:  0.8294115214424548\n",
      "Overall:  0.786092\n",
      "******* \n",
      "Degree:  15 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.7951017385125059\n",
      "1  Size:  77544 \tPerformance:  0.7481558856907047\n",
      "23 Size:  72543 \tPerformance:  0.5184235556842149\n",
      "Overall:  0.700256\n",
      "******* \n",
      "Degree:  16 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.5994715402400088\n",
      "1  Size:  77544 \tPerformance:  0.7964768389559476\n",
      "23 Size:  72543 \tPerformance:  0.5520449940035566\n",
      "Overall:  0.646816\n",
      "******* \n",
      "Degree:  17 \tLambda:  0.000610540229659\n",
      "0  Size:  99913 \tPerformance:  0.7876252339535396\n",
      "1  Size:  77544 \tPerformance:  0.7857216548024347\n",
      "23 Size:  72543 \tPerformance:  0.5211254014860152\n",
      "Overall:  0.709704\n",
      "******* \n",
      "Degree:  2 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.8257884359392671\n",
      "1  Size:  77544 \tPerformance:  0.756138450428144\n",
      "23 Size:  72543 \tPerformance:  0.7696262906138428\n",
      "Overall:  0.787888\n",
      "******* \n",
      "Degree:  3 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.8297618928467767\n",
      "1  Size:  77544 \tPerformance:  0.765681419581141\n",
      "23 Size:  72543 \tPerformance:  0.7917373144204127\n",
      "Overall:  0.798852\n",
      "******* \n",
      "Degree:  4 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.8325643309679421\n",
      "1  Size:  77544 \tPerformance:  0.7764881873516971\n",
      "23 Size:  72543 \tPerformance:  0.8024344182071323\n",
      "Overall:  0.806428\n",
      "******* \n",
      "Degree:  5 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.836697927196661\n",
      "1  Size:  77544 \tPerformance:  0.7803827504384607\n",
      "23 Size:  72543 \tPerformance:  0.8042678135726397\n",
      "Overall:  0.80982\n",
      "******* \n",
      "Degree:  6 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.8389298689860178\n",
      "1  Size:  77544 \tPerformance:  0.7845997111317445\n",
      "23 Size:  72543 \tPerformance:  0.8057565857491419\n",
      "Overall:  0.812452\n",
      "******* \n",
      "Degree:  7 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.8405813057359903\n",
      "1  Size:  77544 \tPerformance:  0.7919503765604045\n",
      "23 Size:  72543 \tPerformance:  0.814413520256951\n",
      "Overall:  0.817904\n",
      "******* \n",
      "Degree:  8 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.8426731256192888\n",
      "1  Size:  77544 \tPerformance:  0.7991978747549778\n",
      "23 Size:  72543 \tPerformance:  0.8246695063617441\n",
      "Overall:  0.823964\n",
      "******* \n",
      "Degree:  9 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.8431735609980683\n",
      "1  Size:  77544 \tPerformance:  0.8029634787991334\n",
      "23 Size:  72543 \tPerformance:  0.8290806831810099\n",
      "Overall:  0.826612\n",
      "******* \n",
      "Degree:  10 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.8365978401209052\n",
      "1  Size:  77544 \tPerformance:  0.8031698132673063\n",
      "23 Size:  72543 \tPerformance:  0.8294804460802558\n",
      "Overall:  0.824164\n",
      "******* \n",
      "Degree:  11 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.6875882017355099\n",
      "1  Size:  77544 \tPerformance:  0.8043304446507789\n",
      "23 Size:  72543 \tPerformance:  0.8301834773858263\n",
      "Overall:  0.765176\n",
      "******* \n",
      "Degree:  12 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.5127260716823636\n",
      "1  Size:  77544 \tPerformance:  0.7998942535850614\n",
      "23 Size:  72543 \tPerformance:  0.8307900141984754\n",
      "Overall:  0.694092\n",
      "******* \n",
      "Degree:  13 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.8063915606577723\n",
      "1  Size:  77544 \tPerformance:  0.7928144021458785\n",
      "23 Size:  72543 \tPerformance:  0.8330093875356686\n",
      "Overall:  0.809904\n",
      "******* \n",
      "Degree:  14 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.7389028454755637\n",
      "1  Size:  77544 \tPerformance:  0.8038919839059115\n",
      "23 Size:  72543 \tPerformance:  0.6624071240505631\n",
      "Overall:  0.736864\n",
      "******* \n",
      "Degree:  15 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.7936604846216209\n",
      "1  Size:  77544 \tPerformance:  0.7829490353863613\n",
      "23 Size:  72543 \tPerformance:  0.6005541540879202\n",
      "Overall:  0.734304\n",
      "******* \n",
      "Degree:  16 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.6921521723899793\n",
      "1  Size:  77544 \tPerformance:  0.6313060971835345\n",
      "23 Size:  72543 \tPerformance:  0.5208083481521304\n",
      "Overall:  0.62356\n",
      "******* \n",
      "Degree:  17 \tLambda:  0.00138949549437\n",
      "0  Size:  99913 \tPerformance:  0.7781770140021819\n",
      "1  Size:  77544 \tPerformance:  0.7968379242752501\n",
      "23 Size:  72543 \tPerformance:  0.7811642749817349\n",
      "Overall:  0.784832\n",
      "******* \n",
      "Degree:  2 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.8257884359392671\n",
      "1  Size:  77544 \tPerformance:  0.756138450428144\n",
      "23 Size:  72543 \tPerformance:  0.7696952152516439\n",
      "Overall:  0.787908\n",
      "******* \n",
      "Degree:  3 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.8297618928467767\n",
      "1  Size:  77544 \tPerformance:  0.765681419581141\n",
      "23 Size:  72543 \tPerformance:  0.7918613787684545\n",
      "Overall:  0.798888\n",
      "******* \n",
      "Degree:  4 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.8325643309679421\n",
      "1  Size:  77544 \tPerformance:  0.7765010832559579\n",
      "23 Size:  72543 \tPerformance:  0.8024206332795721\n",
      "Overall:  0.806428\n",
      "******* \n",
      "Degree:  5 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.836697927196661\n",
      "1  Size:  77544 \tPerformance:  0.7803827504384607\n",
      "23 Size:  72543 \tPerformance:  0.8043229532828805\n",
      "Overall:  0.809836\n",
      "******* \n",
      "Degree:  6 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.8389398776935935\n",
      "1  Size:  77544 \tPerformance:  0.7845997111317445\n",
      "23 Size:  72543 \tPerformance:  0.8057152309664612\n",
      "Overall:  0.812444\n",
      "******* \n",
      "Degree:  7 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.8407214276420486\n",
      "1  Size:  77544 \tPerformance:  0.791911688847622\n",
      "23 Size:  72543 \tPerformance:  0.8144273051845112\n",
      "Overall:  0.817952\n",
      "******* \n",
      "Degree:  8 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.8425530211283817\n",
      "1  Size:  77544 \tPerformance:  0.7992236665634994\n",
      "23 Size:  72543 \tPerformance:  0.8246832912893043\n",
      "Overall:  0.823928\n",
      "******* \n",
      "Degree:  9 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.8431635522904928\n",
      "1  Size:  77544 \tPerformance:  0.8029634787991334\n",
      "23 Size:  72543 \tPerformance:  0.8290255434707691\n",
      "Overall:  0.826592\n",
      "******* \n",
      "Degree:  10 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.7300751653938926\n",
      "1  Size:  77544 \tPerformance:  0.8031698132673063\n",
      "23 Size:  72543 \tPerformance:  0.8294390912975752\n",
      "Overall:  0.78158\n",
      "******* \n",
      "Degree:  11 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.7475003252829961\n",
      "1  Size:  77544 \tPerformance:  0.8038790880016506\n",
      "23 Size:  72543 \tPerformance:  0.8301145527480254\n",
      "Overall:  0.78896\n",
      "******* \n",
      "Degree:  12 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.838339355239058\n",
      "1  Size:  77544 \tPerformance:  0.7970313628391623\n",
      "23 Size:  72543 \tPerformance:  0.677818673062873\n",
      "Overall:  0.778948\n",
      "******* \n",
      "Degree:  13 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.8081731106062274\n",
      "1  Size:  77544 \tPerformance:  0.7995589600742804\n",
      "23 Size:  72543 \tPerformance:  0.8278262547730312\n",
      "Overall:  0.811204\n",
      "******* \n",
      "Degree:  14 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.7314663757468998\n",
      "1  Size:  77544 \tPerformance:  0.7814273186835861\n",
      "23 Size:  72543 \tPerformance:  0.8101677625684077\n",
      "Overall:  0.7698\n",
      "******* \n",
      "Degree:  15 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.772942459940148\n",
      "1  Size:  77544 \tPerformance:  0.7609099350046425\n",
      "23 Size:  72543 \tPerformance:  0.7095929310891471\n",
      "Overall:  0.750828\n",
      "******* \n",
      "Degree:  16 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.7152522694744428\n",
      "1  Size:  77544 \tPerformance:  0.7940782007634375\n",
      "23 Size:  72543 \tPerformance:  0.5681457893938767\n",
      "Overall:  0.697016\n",
      "******* \n",
      "Degree:  17 \tLambda:  0.00316227766017\n",
      "0  Size:  99913 \tPerformance:  0.7937705804049523\n",
      "1  Size:  77544 \tPerformance:  0.8012612194367069\n",
      "23 Size:  72543 \tPerformance:  0.6401168961857105\n",
      "Overall:  0.751508\n",
      "******* \n",
      "Degree:  2 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.8257884359392671\n",
      "1  Size:  77544 \tPerformance:  0.756138450428144\n",
      "23 Size:  72543 \tPerformance:  0.769640075541403\n",
      "Overall:  0.787892\n",
      "******* \n",
      "Degree:  3 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.8297618928467767\n",
      "1  Size:  77544 \tPerformance:  0.765681419581141\n",
      "23 Size:  72543 \tPerformance:  0.7918475938408944\n",
      "Overall:  0.798884\n",
      "******* \n",
      "Degree:  4 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.8325643309679421\n",
      "1  Size:  77544 \tPerformance:  0.7765010832559579\n",
      "23 Size:  72543 \tPerformance:  0.8024482031346926\n",
      "Overall:  0.806436\n",
      "******* \n",
      "Degree:  5 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.836697927196661\n",
      "1  Size:  77544 \tPerformance:  0.7803698545341999\n",
      "23 Size:  72543 \tPerformance:  0.8044608025584825\n",
      "Overall:  0.809872\n",
      "******* \n",
      "Degree:  6 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.8389598951087446\n",
      "1  Size:  77544 \tPerformance:  0.7845997111317445\n",
      "23 Size:  72543 \tPerformance:  0.805701446038901\n",
      "Overall:  0.812448\n",
      "******* \n",
      "Degree:  7 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.8406513666890194\n",
      "1  Size:  77544 \tPerformance:  0.7920019601774476\n",
      "23 Size:  72543 \tPerformance:  0.8144273051845112\n",
      "Overall:  0.817952\n",
      "******* \n",
      "Degree:  8 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.8336853062164082\n",
      "1  Size:  77544 \tPerformance:  0.7992365624677602\n",
      "23 Size:  72543 \tPerformance:  0.8247108611444247\n",
      "Overall:  0.820396\n",
      "******* \n",
      "Degree:  9 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.8431835697056439\n",
      "1  Size:  77544 \tPerformance:  0.8029505828948726\n",
      "23 Size:  72543 \tPerformance:  0.8289841886880884\n",
      "Overall:  0.826584\n",
      "******* \n",
      "Degree:  10 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.6361634622121246\n",
      "1  Size:  77544 \tPerformance:  0.8031569173630455\n",
      "23 Size:  72543 \tPerformance:  0.8294804460802558\n",
      "Overall:  0.744056\n",
      "******* \n",
      "Degree:  11 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.818872419004534\n",
      "1  Size:  77544 \tPerformance:  0.8043691323635613\n",
      "23 Size:  72543 \tPerformance:  0.8301421226031457\n",
      "Overall:  0.817644\n",
      "******* \n",
      "Degree:  12 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.8234964419044568\n",
      "1  Size:  77544 \tPerformance:  0.7993010419890643\n",
      "23 Size:  72543 \tPerformance:  0.8304729608645907\n",
      "Overall:  0.818016\n",
      "******* \n",
      "Degree:  13 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.8142884309349134\n",
      "1  Size:  77544 \tPerformance:  0.7950324976787373\n",
      "23 Size:  72543 \tPerformance:  0.8325820547813021\n",
      "Overall:  0.813624\n",
      "******* \n",
      "Degree:  14 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.7319167675878013\n",
      "1  Size:  77544 \tPerformance:  0.8011451562983596\n",
      "23 Size:  72543 \tPerformance:  0.8290806831810099\n",
      "Overall:  0.781584\n",
      "******* \n",
      "Degree:  15 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.7519141653238317\n",
      "1  Size:  77544 \tPerformance:  0.67311461879707\n",
      "23 Size:  72543 \tPerformance:  0.7475566215899536\n",
      "Overall:  0.726208\n",
      "******* \n",
      "Degree:  16 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.7169737671774443\n",
      "1  Size:  77544 \tPerformance:  0.7969926751263798\n",
      "23 Size:  72543 \tPerformance:  0.5104834374095364\n",
      "Overall:  0.681876\n",
      "******* \n",
      "Degree:  17 \tLambda:  0.00719685673001\n",
      "0  Size:  99913 \tPerformance:  0.7530151231571467\n",
      "1  Size:  77544 \tPerformance:  0.8000232126276694\n",
      "23 Size:  72543 \tPerformance:  0.7396854279530761\n",
      "Overall:  0.763728\n",
      "******* \n",
      "Degree:  2 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.8257884359392671\n",
      "1  Size:  77544 \tPerformance:  0.756138450428144\n",
      "23 Size:  72543 \tPerformance:  0.7697641398894449\n",
      "Overall:  0.787928\n",
      "******* \n",
      "Degree:  3 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.8297618928467767\n",
      "1  Size:  77544 \tPerformance:  0.765681419581141\n",
      "23 Size:  72543 \tPerformance:  0.7918062390582138\n",
      "Overall:  0.798872\n",
      "******* \n",
      "Degree:  4 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.8325643309679421\n",
      "1  Size:  77544 \tPerformance:  0.7765010832559579\n",
      "23 Size:  72543 \tPerformance:  0.8025722674827344\n",
      "Overall:  0.806472\n",
      "******* \n",
      "Degree:  5 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.836697927196661\n",
      "1  Size:  77544 \tPerformance:  0.7803698545341999\n",
      "23 Size:  72543 \tPerformance:  0.8044745874860427\n",
      "Overall:  0.809876\n",
      "******* \n",
      "Degree:  6 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.8389598951087446\n",
      "1  Size:  77544 \tPerformance:  0.7845997111317445\n",
      "23 Size:  72543 \tPerformance:  0.805701446038901\n",
      "Overall:  0.812448\n",
      "******* \n",
      "Degree:  7 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.8406113318587171\n",
      "1  Size:  77544 \tPerformance:  0.7919503765604045\n",
      "23 Size:  72543 \tPerformance:  0.8144273051845112\n",
      "Overall:  0.81792\n",
      "******* \n",
      "Degree:  8 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.8426230820814108\n",
      "1  Size:  77544 \tPerformance:  0.7988754771484576\n",
      "23 Size:  72543 \tPerformance:  0.8247660008546656\n",
      "Overall:  0.823872\n",
      "******* \n",
      "Degree:  9 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.8432135958283706\n",
      "1  Size:  77544 \tPerformance:  0.8029634787991334\n",
      "23 Size:  72543 \tPerformance:  0.8289152640502875\n",
      "Overall:  0.82658\n",
      "******* \n",
      "Degree:  10 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.836577822705754\n",
      "1  Size:  77544 \tPerformance:  0.8031827091715671\n",
      "23 Size:  72543 \tPerformance:  0.8295355857904967\n",
      "Overall:  0.824176\n",
      "******* \n",
      "Degree:  11 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.6949846366338714\n",
      "1  Size:  77544 \tPerformance:  0.8043433405550398\n",
      "23 Size:  72543 \tPerformance:  0.8301283376755855\n",
      "Overall:  0.76812\n",
      "******* \n",
      "Degree:  12 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.807572588151692\n",
      "1  Size:  77544 \tPerformance:  0.80418858970391\n",
      "23 Size:  72543 \tPerformance:  0.8311622072426009\n",
      "Overall:  0.813368\n",
      "******* \n",
      "Degree:  13 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.8216748571256993\n",
      "1  Size:  77544 \tPerformance:  0.7995331682657588\n",
      "23 Size:  72543 \tPerformance:  0.8322512165198572\n",
      "Overall:  0.817876\n",
      "******* \n",
      "Degree:  14 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.6975468657732227\n",
      "1  Size:  77544 \tPerformance:  0.7959996904982978\n",
      "23 Size:  72543 \tPerformance:  0.8307210895606744\n",
      "Overall:  0.766728\n",
      "******* \n",
      "Degree:  15 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.7591104260706815\n",
      "1  Size:  77544 \tPerformance:  0.7120215619519241\n",
      "23 Size:  72543 \tPerformance:  0.678756048136967\n",
      "Overall:  0.721188\n",
      "******* \n",
      "Degree:  16 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.6574119483951038\n",
      "1  Size:  77544 \tPerformance:  0.7958836273599504\n",
      "23 Size:  72543 \tPerformance:  0.6190121720910357\n",
      "Overall:  0.68922\n",
      "******* \n",
      "Degree:  17 \tLambda:  0.0163789370695\n",
      "0  Size:  99913 \tPerformance:  0.796833244923083\n",
      "1  Size:  77544 \tPerformance:  0.7968895078922934\n",
      "23 Size:  72543 \tPerformance:  0.6116785906290063\n",
      "Overall:  0.743124\n",
      "******* \n",
      "Degree:  2 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.8257884359392671\n",
      "1  Size:  77544 \tPerformance:  0.756138450428144\n",
      "23 Size:  72543 \tPerformance:  0.7697779248170051\n",
      "Overall:  0.787932\n",
      "******* \n",
      "Degree:  3 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.8297618928467767\n",
      "1  Size:  77544 \tPerformance:  0.765681419581141\n",
      "23 Size:  72543 \tPerformance:  0.7917648842755332\n",
      "Overall:  0.79886\n",
      "******* \n",
      "Degree:  4 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.8325643309679421\n",
      "1  Size:  77544 \tPerformance:  0.7764881873516971\n",
      "23 Size:  72543 \tPerformance:  0.8025722674827344\n",
      "Overall:  0.806468\n",
      "******* \n",
      "Degree:  5 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.836697927196661\n",
      "1  Size:  77544 \tPerformance:  0.7803698545341999\n",
      "23 Size:  72543 \tPerformance:  0.8044883724136029\n",
      "Overall:  0.80988\n",
      "******* \n",
      "Degree:  6 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.8389699038163202\n",
      "1  Size:  77544 \tPerformance:  0.7845997111317445\n",
      "23 Size:  72543 \tPerformance:  0.8057703706767021\n",
      "Overall:  0.812472\n",
      "******* \n",
      "Degree:  7 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.8405312621981124\n",
      "1  Size:  77544 \tPerformance:  0.7919503765604045\n",
      "23 Size:  72543 \tPerformance:  0.8143859504018307\n",
      "Overall:  0.817876\n",
      "******* \n",
      "Degree:  8 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.8425530211283817\n",
      "1  Size:  77544 \tPerformance:  0.7992107706592386\n",
      "23 Size:  72543 \tPerformance:  0.824793570709786\n",
      "Overall:  0.823956\n",
      "******* \n",
      "Degree:  9 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.8431435348753415\n",
      "1  Size:  77544 \tPerformance:  0.802989270607655\n",
      "23 Size:  72543 \tPerformance:  0.8289704037605282\n",
      "Overall:  0.826576\n",
      "******* \n",
      "Degree:  10 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.8178515308318237\n",
      "1  Size:  77544 \tPerformance:  0.8031698132673063\n",
      "23 Size:  72543 \tPerformance:  0.829494231007816\n",
      "Overall:  0.816676\n",
      "******* \n",
      "Degree:  11 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.8260086275059302\n",
      "1  Size:  77544 \tPerformance:  0.8043820282678221\n",
      "23 Size:  72543 \tPerformance:  0.830100767820465\n",
      "Overall:  0.820488\n",
      "******* \n",
      "Degree:  12 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.805540820513847\n",
      "1  Size:  77544 \tPerformance:  0.8028216238522645\n",
      "23 Size:  72543 \tPerformance:  0.830100767820465\n",
      "Overall:  0.811824\n",
      "******* \n",
      "Degree:  13 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.827970334190746\n",
      "1  Size:  77544 \tPerformance:  0.7809243784174147\n",
      "23 Size:  72543 \tPerformance:  0.8304867457921509\n",
      "Overall:  0.814108\n",
      "******* \n",
      "Degree:  14 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.6655290102389079\n",
      "1  Size:  77544 \tPerformance:  0.7849607964510472\n",
      "23 Size:  72543 \tPerformance:  0.8256482362185187\n",
      "Overall:  0.749036\n",
      "******* \n",
      "Degree:  15 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.5931860718825378\n",
      "1  Size:  77544 \tPerformance:  0.7322552357371299\n",
      "23 Size:  72543 \tPerformance:  0.5747901244778959\n",
      "Overall:  0.630984\n",
      "******* \n",
      "Degree:  16 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.7313062364256904\n",
      "1  Size:  77544 \tPerformance:  0.5906839987619932\n",
      "23 Size:  72543 \tPerformance:  0.5566629447362255\n",
      "Overall:  0.637012\n",
      "******* \n",
      "Degree:  17 \tLambda:  0.0372759372031\n",
      "0  Size:  99913 \tPerformance:  0.7970734539048973\n",
      "1  Size:  77544 \tPerformance:  0.7992107706592386\n",
      "23 Size:  72543 \tPerformance:  0.770977213514743\n",
      "Overall:  0.790164\n",
      "******* \n",
      "Degree:  2 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.8257884359392671\n",
      "1  Size:  77544 \tPerformance:  0.756138450428144\n",
      "23 Size:  72543 \tPerformance:  0.7698330645272459\n",
      "Overall:  0.787948\n",
      "******* \n",
      "Degree:  3 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.8297618928467767\n",
      "1  Size:  77544 \tPerformance:  0.765681419581141\n",
      "23 Size:  72543 \tPerformance:  0.7917786692030934\n",
      "Overall:  0.798864\n",
      "******* \n",
      "Degree:  4 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.8325643309679421\n",
      "1  Size:  77544 \tPerformance:  0.7764881873516971\n",
      "23 Size:  72543 \tPerformance:  0.8025584825551741\n",
      "Overall:  0.806464\n",
      "******* \n",
      "Degree:  5 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.836697927196661\n",
      "1  Size:  77544 \tPerformance:  0.7803698545341999\n",
      "23 Size:  72543 \tPerformance:  0.8044332327033621\n",
      "Overall:  0.809864\n",
      "******* \n",
      "Degree:  6 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.8390499734769249\n",
      "1  Size:  77544 \tPerformance:  0.7845868152274837\n",
      "23 Size:  72543 \tPerformance:  0.8057703706767021\n",
      "Overall:  0.8125\n",
      "******* \n",
      "Degree:  7 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.8406213405662927\n",
      "1  Size:  77544 \tPerformance:  0.7919503765604045\n",
      "23 Size:  72543 \tPerformance:  0.8144548750396317\n",
      "Overall:  0.817932\n",
      "******* \n",
      "Degree:  8 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.8425330037132305\n",
      "1  Size:  77544 \tPerformance:  0.7992107706592386\n",
      "23 Size:  72543 \tPerformance:  0.824793570709786\n",
      "Overall:  0.823948\n",
      "******* \n",
      "Degree:  9 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.842863291063225\n",
      "1  Size:  77544 \tPerformance:  0.8030150624161766\n",
      "23 Size:  72543 \tPerformance:  0.8290393283983293\n",
      "Overall:  0.826492\n",
      "******* \n",
      "Degree:  10 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.8391600692602564\n",
      "1  Size:  77544 \tPerformance:  0.8032471886928712\n",
      "23 Size:  72543 \tPerformance:  0.8295907255007375\n",
      "Overall:  0.825244\n",
      "******* \n",
      "Degree:  11 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.8374285628496793\n",
      "1  Size:  77544 \tPerformance:  0.8043175487465182\n",
      "23 Size:  72543 \tPerformance:  0.8300456281102243\n",
      "Overall:  0.825016\n",
      "******* \n",
      "Degree:  12 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.8020577902775414\n",
      "1  Size:  77544 \tPerformance:  0.8038919839059115\n",
      "23 Size:  72543 \tPerformance:  0.8318514536206112\n",
      "Overall:  0.811272\n",
      "******* \n",
      "Degree:  13 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.8344659854073043\n",
      "1  Size:  77544 \tPerformance:  0.7995589600742804\n",
      "23 Size:  72543 \tPerformance:  0.8276194808596281\n",
      "Overall:  0.821652\n",
      "******* \n",
      "Degree:  14 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.6314393522364457\n",
      "1  Size:  77544 \tPerformance:  0.6114850923346745\n",
      "23 Size:  72543 \tPerformance:  0.8284741463683608\n",
      "Overall:  0.682424\n",
      "******* \n",
      "Degree:  15 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.7661365387887462\n",
      "1  Size:  77544 \tPerformance:  0.7759465593727433\n",
      "23 Size:  72543 \tPerformance:  0.779964986283997\n",
      "Overall:  0.773192\n",
      "******* \n",
      "Degree:  16 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.7847627435869207\n",
      "1  Size:  77544 \tPerformance:  0.7161869390281647\n",
      "23 Size:  72543 \tPerformance:  0.6751306121886329\n",
      "Overall:  0.73168\n",
      "******* \n",
      "Degree:  17 \tLambda:  0.0848342898244\n",
      "0  Size:  99913 \tPerformance:  0.793290162441324\n",
      "1  Size:  77544 \tPerformance:  0.8030924378417414\n",
      "23 Size:  72543 \tPerformance:  0.799663647767531\n",
      "Overall:  0.79818\n",
      "******* \n",
      "Degree:  2 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.8257884359392671\n",
      "1  Size:  77544 \tPerformance:  0.756138450428144\n",
      "23 Size:  72543 \tPerformance:  0.7698330645272459\n",
      "Overall:  0.787948\n",
      "******* \n",
      "Degree:  3 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.8297618928467767\n",
      "1  Size:  77544 \tPerformance:  0.765681419581141\n",
      "23 Size:  72543 \tPerformance:  0.7918062390582138\n",
      "Overall:  0.798872\n",
      "******* \n",
      "Degree:  4 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.8325843483830933\n",
      "1  Size:  77544 \tPerformance:  0.7764881873516971\n",
      "23 Size:  72543 \tPerformance:  0.8025722674827344\n",
      "Overall:  0.806476\n",
      "******* \n",
      "Degree:  5 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.8366879184890855\n",
      "1  Size:  77544 \tPerformance:  0.7803569586299391\n",
      "23 Size:  72543 \tPerformance:  0.8044470176309224\n",
      "Overall:  0.80986\n",
      "******* \n",
      "Degree:  6 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.8389999299390469\n",
      "1  Size:  77544 \tPerformance:  0.7845868152274837\n",
      "23 Size:  72543 \tPerformance:  0.8057979405318225\n",
      "Overall:  0.812488\n",
      "******* \n",
      "Degree:  7 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.8406713841041706\n",
      "1  Size:  77544 \tPerformance:  0.7919374806561437\n",
      "23 Size:  72543 \tPerformance:  0.8144686599671919\n",
      "Overall:  0.817952\n",
      "******* \n",
      "Degree:  8 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.8426631169117131\n",
      "1  Size:  77544 \tPerformance:  0.7992107706592386\n",
      "23 Size:  72543 \tPerformance:  0.824793570709786\n",
      "Overall:  0.824\n",
      "******* \n",
      "Degree:  9 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.8434037612723069\n",
      "1  Size:  77544 \tPerformance:  0.8029505828948726\n",
      "23 Size:  72543 \tPerformance:  0.8289841886880884\n",
      "Overall:  0.826672\n",
      "******* \n",
      "Degree:  10 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.8341156806421587\n",
      "1  Size:  77544 \tPerformance:  0.8031827091715671\n",
      "23 Size:  72543 \tPerformance:  0.8295769405731773\n",
      "Overall:  0.823204\n",
      "******* \n",
      "Degree:  11 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.8411417933602234\n",
      "1  Size:  77544 \tPerformance:  0.8042917569379965\n",
      "23 Size:  72543 \tPerformance:  0.8301421226031457\n",
      "Overall:  0.82652\n",
      "******* \n",
      "Degree:  12 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.7911482990201475\n",
      "1  Size:  77544 \tPerformance:  0.7999329412978438\n",
      "23 Size:  72543 \tPerformance:  0.8315895399969673\n",
      "Overall:  0.805608\n",
      "******* \n",
      "Degree:  13 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.8393802608269194\n",
      "1  Size:  77544 \tPerformance:  0.8055039719385123\n",
      "23 Size:  72543 \tPerformance:  0.8329680327529879\n",
      "Overall:  0.827012\n",
      "******* \n",
      "Degree:  14 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.5192517490216488\n",
      "1  Size:  77544 \tPerformance:  0.8039693593314763\n",
      "23 Size:  72543 \tPerformance:  0.8267648153508953\n",
      "Overall:  0.696796\n",
      "******* \n",
      "Degree:  15 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.7561778747510334\n",
      "1  Size:  77544 \tPerformance:  0.7977277416692459\n",
      "23 Size:  72543 \tPerformance:  0.7902623271714707\n",
      "Overall:  0.778956\n",
      "******* \n",
      "Degree:  16 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.7892466445807853\n",
      "1  Size:  77544 \tPerformance:  0.8038404002888683\n",
      "23 Size:  72543 \tPerformance:  0.7106543705112829\n",
      "Overall:  0.770968\n",
      "******* \n",
      "Degree:  17 \tLambda:  0.193069772888\n",
      "0  Size:  99913 \tPerformance:  0.7926596138640617\n",
      "1  Size:  77544 \tPerformance:  0.7923243577839678\n",
      "23 Size:  72543 \tPerformance:  0.7987400576209972\n",
      "Overall:  0.79432\n",
      "******* \n",
      "Degree:  2 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.8257884359392671\n",
      "1  Size:  77544 \tPerformance:  0.756138450428144\n",
      "23 Size:  72543 \tPerformance:  0.7698330645272459\n",
      "Overall:  0.787948\n",
      "******* \n",
      "Degree:  3 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.8297618928467767\n",
      "1  Size:  77544 \tPerformance:  0.765681419581141\n",
      "23 Size:  72543 \tPerformance:  0.7918062390582138\n",
      "Overall:  0.798872\n",
      "******* \n",
      "Degree:  4 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.8325843483830933\n",
      "1  Size:  77544 \tPerformance:  0.7765010832559579\n",
      "23 Size:  72543 \tPerformance:  0.8025860524102946\n",
      "Overall:  0.806484\n",
      "******* \n",
      "Degree:  5 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.8366679010739343\n",
      "1  Size:  77544 \tPerformance:  0.7803698545341999\n",
      "23 Size:  72543 \tPerformance:  0.8044745874860427\n",
      "Overall:  0.809864\n",
      "******* \n",
      "Degree:  6 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.8388898341557155\n",
      "1  Size:  77544 \tPerformance:  0.7845868152274837\n",
      "23 Size:  72543 \tPerformance:  0.8058117254593827\n",
      "Overall:  0.812448\n",
      "******* \n",
      "Degree:  7 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.8404111577072053\n",
      "1  Size:  77544 \tPerformance:  0.791976168368926\n",
      "23 Size:  72543 \tPerformance:  0.8144686599671919\n",
      "Overall:  0.81786\n",
      "******* \n",
      "Degree:  8 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.8426831343268644\n",
      "1  Size:  77544 \tPerformance:  0.7992107706592386\n",
      "23 Size:  72543 \tPerformance:  0.8247108611444247\n",
      "Overall:  0.823984\n",
      "******* \n",
      "Degree:  9 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.8431035000450392\n",
      "1  Size:  77544 \tPerformance:  0.8029505828948726\n",
      "23 Size:  72543 \tPerformance:  0.8288463394124864\n",
      "Overall:  0.826512\n",
      "******* \n",
      "Degree:  10 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.833815419414891\n",
      "1  Size:  77544 \tPerformance:  0.8031440214587847\n",
      "23 Size:  72543 \tPerformance:  0.8295907255007375\n",
      "Overall:  0.823076\n",
      "******* \n",
      "Degree:  11 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.842252759901114\n",
      "1  Size:  77544 \tPerformance:  0.8043175487465182\n",
      "23 Size:  72543 \tPerformance:  0.8300180582551039\n",
      "Overall:  0.826936\n",
      "******* \n",
      "Degree:  12 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.7123797704002481\n",
      "1  Size:  77544 \tPerformance:  0.8051686784277313\n",
      "23 Size:  72543 \tPerformance:  0.7596735729153743\n",
      "Overall:  0.754884\n",
      "******* \n",
      "Degree:  13 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.8413319588041597\n",
      "1  Size:  77544 \tPerformance:  0.8039435675229547\n",
      "23 Size:  72543 \tPerformance:  0.8327612588395847\n",
      "Overall:  0.827248\n",
      "******* \n",
      "Degree:  14 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.6505860098285509\n",
      "1  Size:  77544 \tPerformance:  0.8035953781079129\n",
      "23 Size:  72543 \tPerformance:  0.8317549591276898\n",
      "Overall:  0.750616\n",
      "******* \n",
      "Degree:  15 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.7387226887392031\n",
      "1  Size:  77544 \tPerformance:  0.7613226039409884\n",
      "23 Size:  72543 \tPerformance:  0.8051500489364929\n",
      "Overall:  0.765008\n",
      "******* \n",
      "Degree:  16 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.6591334460981053\n",
      "1  Size:  77544 \tPerformance:  0.7767332095326525\n",
      "23 Size:  72543 \tPerformance:  0.6063300387356465\n",
      "Overall:  0.680288\n",
      "******* \n",
      "Degree:  17 \tLambda:  0.439397056076\n",
      "0  Size:  99913 \tPerformance:  0.7915186212004444\n",
      "1  Size:  77544 \tPerformance:  0.8030666460332199\n",
      "23 Size:  72543 \tPerformance:  0.8252071185365921\n",
      "Overall:  0.804876\n",
      "******* \n",
      "Degree:  2 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.8257884359392671\n",
      "1  Size:  77544 \tPerformance:  0.756138450428144\n",
      "23 Size:  72543 \tPerformance:  0.7698330645272459\n",
      "Overall:  0.787948\n",
      "******* \n",
      "Degree:  3 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.8297618928467767\n",
      "1  Size:  77544 \tPerformance:  0.765681419581141\n",
      "23 Size:  72543 \tPerformance:  0.791820023985774\n",
      "Overall:  0.798876\n",
      "******* \n",
      "Degree:  4 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.8325643309679421\n",
      "1  Size:  77544 \tPerformance:  0.7764881873516971\n",
      "23 Size:  72543 \tPerformance:  0.8025860524102946\n",
      "Overall:  0.806472\n",
      "******* \n",
      "Degree:  5 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.836697927196661\n",
      "1  Size:  77544 \tPerformance:  0.7804085422469824\n",
      "23 Size:  72543 \tPerformance:  0.8044883724136029\n",
      "Overall:  0.809892\n",
      "******* \n",
      "Degree:  6 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.8388197732026863\n",
      "1  Size:  77544 \tPerformance:  0.784573919323223\n",
      "23 Size:  72543 \tPerformance:  0.8058392953145032\n",
      "Overall:  0.812424\n",
      "******* \n",
      "Degree:  7 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.8395904436860069\n",
      "1  Size:  77544 \tPerformance:  0.7919632724646652\n",
      "23 Size:  72543 \tPerformance:  0.8144410901120714\n",
      "Overall:  0.81752\n",
      "******* \n",
      "Degree:  8 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.8426030646662597\n",
      "1  Size:  77544 \tPerformance:  0.7991978747549778\n",
      "23 Size:  72543 \tPerformance:  0.8248487104200267\n",
      "Overall:  0.823988\n",
      "******* \n",
      "Degree:  9 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.843303674196551\n",
      "1  Size:  77544 \tPerformance:  0.802924791086351\n",
      "23 Size:  72543 \tPerformance:  0.8287222750644445\n",
      "Overall:  0.826548\n",
      "******* \n",
      "Degree:  10 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.8406713841041706\n",
      "1  Size:  77544 \tPerformance:  0.8030021665119158\n",
      "23 Size:  72543 \tPerformance:  0.8295769405731773\n",
      "Overall:  0.825768\n",
      "******* \n",
      "Degree:  11 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.842913334601103\n",
      "1  Size:  77544 \tPerformance:  0.8043046528422573\n",
      "23 Size:  72543 \tPerformance:  0.8298526391243815\n",
      "Overall:  0.827148\n",
      "******* \n",
      "Degree:  12 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.7729024251098455\n",
      "1  Size:  77544 \tPerformance:  0.8051041989064274\n",
      "23 Size:  72543 \tPerformance:  0.8311346373874805\n",
      "Overall:  0.799788\n",
      "******* \n",
      "Degree:  13 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.842252759901114\n",
      "1  Size:  77544 \tPerformance:  0.8021510368307025\n",
      "23 Size:  72543 \tPerformance:  0.8323477110127786\n",
      "Overall:  0.82694\n",
      "******* \n",
      "Degree:  14 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.7009498263489236\n",
      "1  Size:  77544 \tPerformance:  0.5778009904054473\n",
      "23 Size:  72543 \tPerformance:  0.8289979736156486\n",
      "Overall:  0.699908\n",
      "******* \n",
      "Degree:  15 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.7465695154784663\n",
      "1  Size:  77544 \tPerformance:  0.7988109976271536\n",
      "23 Size:  72543 \tPerformance:  0.7480942337648016\n",
      "Overall:  0.763216\n",
      "******* \n",
      "Degree:  16 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.8011670153033139\n",
      "1  Size:  77544 \tPerformance:  0.7788352419271639\n",
      "23 Size:  72543 \tPerformance:  0.5385495499221151\n",
      "Overall:  0.718036\n",
      "******* \n",
      "Degree:  17 \tLambda:  1.0\n",
      "0  Size:  99913 \tPerformance:  0.7874650946323302\n",
      "1  Size:  77544 \tPerformance:  0.7646497472402765\n",
      "23 Size:  72543 \tPerformance:  0.7629268158195829\n",
      "Overall:  0.773268\n",
      "******* \n",
      "0  : \n",
      "Max p:  0.8434037612723069\n",
      "With d:  9\n",
      "With l:  0.193069772888\n",
      "1  : \n",
      "Max p:  0.8057618900237284\n",
      "With d:  12\n",
      "With l:  1e-05\n",
      "23 : \n",
      "Max p:  0.8330093875356686\n",
      "With d:  13\n",
      "With l:  0.00138949549437\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split the data\n",
    "i_0, i_1, i_23 = split_dataset_wrt22(tX)\n",
    "tx_0 =  tX[i_0]\n",
    "y_0 =   y[i_0]\n",
    "tx_1 =  tX[i_1]\n",
    "y_1 =   y[i_1]\n",
    "tx_23 = tX[i_23]\n",
    "y_23 =  y[i_23]\n",
    "\n",
    "# Standardize the data\n",
    "std_tx_0 = standardize_0(tx_0)\n",
    "std_tx_1 = standardize_1(tx_1)\n",
    "std_tx_23 = standardize_23(tx_23)\n",
    "\n",
    "# Add the feature\n",
    "# std_tx_0 = add_feature(std_tx_0)\n",
    "# std_tx_1 = add_feature(std_tx_1)\n",
    "# std_tx_23 = add_feature(std_tx_23)\n",
    "\n",
    "# polynomial degree\n",
    "degrees = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ,12, 13, 14, 15, 16, 17]\n",
    "lambdas = np.logspace(-5, 0, 15)\n",
    "\n",
    "p_array = [0, 0, 0]\n",
    "d_array = [0, 0, 0]\n",
    "l_array = [0, 0, 0]\n",
    "\n",
    "def update_arrays(lambda_, degree, p0, p1, p23):\n",
    "    p = [p0, p1, p23]\n",
    "    for i in range(3):\n",
    "        if p[i] > p_array[i]:\n",
    "            p_array[i] = p[i]\n",
    "            d_array[i] = degree\n",
    "            l_array[i] = lambda_\n",
    "            \n",
    "    \n",
    "def print_stat(p_array, d_array, l_array):\n",
    "    string = ['0 ', '1 ', '23']\n",
    "    for i in range(3):\n",
    "        print(string[i], \": \")\n",
    "        print(\"Max p: \", p_array[i])\n",
    "        print(\"With d: \", d_array[i])\n",
    "        print(\"With l: \", l_array[i])\n",
    "        \n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    for degree in degrees:\n",
    "        print(\"Degree: \", degree, \"\\tLambda: \", lambda_)\n",
    "        # Build the polynomial \n",
    "        matrix_std_tx_0 = build_poly(std_tx_0, degree)\n",
    "        matrix_std_tx_1 = build_poly(std_tx_1, degree)\n",
    "        matrix_std_tx_23 = build_poly(std_tx_23, degree)\n",
    "\n",
    "        weights_0 = ridge_regression(y_0, matrix_std_tx_0, lambda_)\n",
    "        weights_1 = ridge_regression(y_1, matrix_std_tx_1, lambda_)\n",
    "        weights_23 = ridge_regression(y_23, matrix_std_tx_23, lambda_)\n",
    "\n",
    "        # invoke the performance function to get a rough estimate on how well we are doing \n",
    "        # on the data that we just trained. \n",
    "        # \n",
    "        # We suppose to use cross-validation for this step. \n",
    "        # However, due to the characteristics of the data, we think that evaluate on the original\n",
    "        # training dataset will give us a reference on how well we are doing\n",
    "        # This step is only an indication on whether we did anything REALLY wrong or not.\n",
    "        p0 = performance(weights_0, y_0, matrix_std_tx_0)\n",
    "        p1 = performance(weights_1, y_1, matrix_std_tx_1)\n",
    "        p23 = performance(weights_23, y_23, matrix_std_tx_23)\n",
    "        print(\"0  Size: \", len(y_0), \"\\tPerformance: \", p0)\n",
    "        print(\"1  Size: \", len(y_1), \"\\tPerformance: \", p1)\n",
    "        print(\"23 Size: \", len(y_23), \"\\tPerformance: \", p23)\n",
    "        print(\"Overall: \", (p0 * len(y_0) + len(y_1) * p1 + p23 * len(y_23)) / len(y))\n",
    "        print(\"******* \")\n",
    "        update_arrays(lambda_, degree, p0, p1, p23)\n",
    "\n",
    "print_stat(p_array, d_array, l_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0  : \n",
    "# Max p:  0.8434037612723069\n",
    "# With d:  9\n",
    "# With l:  0.193069772888\n",
    "# 1  : \n",
    "# Max p:  0.8057618900237284\n",
    "# With d:  12\n",
    "# With l:  1e-05\n",
    "# 23 : \n",
    "# Max p:  0.8330093875356686\n",
    "# With d:  13\n",
    "# With l:  0.00138949549437\n",
    "\n",
    "degree_0  = 9\n",
    "degree_1  = 12\n",
    "degree_23 = 13\n",
    "matrix_std_tx_0 = build_poly(std_tx_0, degree_0)\n",
    "matrix_std_tx_1 = build_poly(std_tx_1, degree_1)\n",
    "matrix_std_tx_23 = build_poly(std_tx_23, degree_23)\n",
    "\n",
    "weights_0 = ridge_regression(y_0, matrix_std_tx_0, 0.193069772888)\n",
    "weights_1 = ridge_regression(y_1, matrix_std_tx_1, 1e-05)\n",
    "weights_23 = ridge_regression(y_23, matrix_std_tx_23, 0.00138949549437)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load test data\n",
    "DATA_TEST_PATH = '../../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "i_0_test, i_1_test, i_23_test = split_dataset_wrt22(tX_test)\n",
    "\n",
    "# split tx into 3 set \n",
    "tx_0_test = tX_test[i_0_test]\n",
    "tx_1_test = tX_test[i_1_test]\n",
    "tx_23_test = tX_test[i_23_test]\n",
    "\n",
    "# standardize\n",
    "std_tx_0_test = standardize_0(tx_0_test)\n",
    "std_tx_1_test = standardize_1(tx_1_test)\n",
    "std_tx_23_test = standardize_23(tx_23_test)\n",
    "\n",
    "# add feature\n",
    "# std_tx_0_test = add_feature(std_tx_0_test)\n",
    "# std_tx_1_test = add_feature(std_tx_1_test)\n",
    "# std_tx_23_test = add_feature(std_tx_23_test)\n",
    "\n",
    "# split index into 3 features\n",
    "ids_0_test = ids_test[i_0_test]\n",
    "ids_1_test = ids_test[i_1_test]\n",
    "ids_23_test = ids_test[i_23_test]\n",
    "\n",
    "# Make prediction\n",
    "y_pred_0 = predict_labels(weights_0, build_poly(std_tx_0_test, degree_0))\n",
    "y_pred_1 = predict_labels(weights_1, build_poly(std_tx_1_test, degree_1))\n",
    "y_pred_23 = predict_labels(weights_23, build_poly(std_tx_23_test, degree_23))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate everything into one\n",
    "y_pred = np.concatenate((y_pred_0, y_pred_1, y_pred_23), axis=0)\n",
    "ids_test = np.concatenate((ids_0_test, ids_1_test, ids_23_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output to file\n",
    "OUTPUT_PATH = '../../data/output.csv' # TODO: fill in desired name of output file for submission\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
